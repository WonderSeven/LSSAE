import pdb

import torch
import torch.nn as nn

if __name__ == '__main__':
    # ckpt_path = '/data/qtx/Projects/Personal/LSSAE_DG_His/SEDG_baseline/logs/ToyCircle_CovariantShift/SEDG_final/ckpt/best_seed-0.pth.tar'
    ckpt_path = '/data/qtx/Projects/Personal/LSSAE_DG_His/SEDG_baseline/logs/ToyCircle_DatasetShift/SEDG_Con/ckpt/best_seed-0.pth.tar'
    # ckpt_path = '/data/qtx/Projects/Personal/LSSAE_DG_His/SEDG_baseline/logs/ToySine_ConvariantShift/SEDG_final/ckpt/best_seed-0.pth.tar'
    # ckpt_path = '/data/qtx/Projects/Personal/LSSAE_DG_His/SEDG_baseline/logs/ToySine_DatasetShift/SEDG_single/ckpt/best_seed-0.pth.tar'
    # ckpt_path = '/data/qtx/Projects/Personal/LSSAE_DG_His/SEDG_baseline/logs/PowerSupply/LSSVAE/LSSVAE_19/ckpt/best_seed-0.pth.tar'
    # ckpt_path = '/data/qtx/Projects/Github/LSSAE/logs/ToyCircle/2_/ckpt/best_seed-0.pth.tar'

    ckpt = torch.load(ckpt_path)
    pretrained_params = ckpt['algorithm']

    # pdb.set_trace()

    for p in pretrained_params.keys():
        print(p, pretrained_params[p].shape)

        # if isinstance(p, str):
        #     print(p, pre)


# latent_v_priors torch.Size([16, 2])
# latent_w_priors torch.Size([16, 40])
# num_batches_tracked torch.Size([])
# model_func.input.weight torch.Size([512, 2])
# model_func.input.bias torch.Size([512])
# model_func.hiddens.0.weight torch.Size([512, 512])
# model_func.hiddens.0.bias torch.Size([512])
# model_func.hiddens.1.weight torch.Size([512, 512])
# model_func.hiddens.1.bias torch.Size([512])
# model_func.output.weight torch.Size([512, 512])
# model_func.output.bias torch.Size([512])
# cla_func.linear.weight torch.Size([2, 20])
# cla_func.linear.bias torch.Size([2])
# gaussian.dummy_param torch.Size([0])
# qzx.model_func.input.weight torch.Size([512, 2])
# qzx.model_func.input.bias torch.Size([512])
# qzx.model_func.hiddens.0.weight torch.Size([512, 512])
# qzx.model_func.hiddens.0.bias torch.Size([512])
# qzx.model_func.hiddens.1.weight torch.Size([512, 512])
# qzx.model_func.hiddens.1.bias torch.Size([512])
# qzx.model_func.output.weight torch.Size([512, 512])
# qzx.model_func.output.bias torch.Size([512])
# qzx.fc_layer.weight torch.Size([40, 512])
# qzx.fc_layer.bias torch.Size([40])
# qzv.linear1.0.weight torch.Size([2, 2])
# qzv.linear1.0.bias torch.Size([2])
# qzv.linear1.1.weight torch.Size([2])
# qzv.linear1.1.bias torch.Size([2])
# qzv.linear1.1.running_mean torch.Size([2])
# qzv.linear1.1.running_var torch.Size([2])
# qzv.linear1.1.num_batches_tracked torch.Size([])
# qzv.linear2.0.weight torch.Size([2, 2])
# qzv.linear2.0.bias torch.Size([2])
# qzw.model_func.input.weight torch.Size([512, 2])
# qzw.model_func.input.bias torch.Size([512])
# qzw.model_func.hiddens.0.weight torch.Size([512, 512])
# qzw.model_func.hiddens.0.bias torch.Size([512])
# qzw.model_func.hiddens.1.weight torch.Size([512, 512])
# qzw.model_func.hiddens.1.bias torch.Size([512])
# qzw.model_func.output.weight torch.Size([512, 512])
# qzw.model_func.output.bias torch.Size([512])
# qzw.fc_layer.weight torch.Size([40, 512])
# qzw.fc_layer.bias torch.Size([40])
# px.model.0.weight torch.Size([16, 40])
# px.model.0.bias torch.Size([16])
# px.model.2.weight torch.Size([64, 16])
# px.model.2.bias torch.Size([64])
# px.model.3.weight torch.Size([64])
# px.model.3.bias torch.Size([64])
# px.model.3.running_mean torch.Size([64])
# px.model.3.running_var torch.Size([64])
# px.model.3.num_batches_tracked torch.Size([])
# px.model.5.weight torch.Size([128, 64])
# px.model.5.bias torch.Size([128])
# px.model.6.weight torch.Size([128])
# px.model.6.bias torch.Size([128])
# px.model.6.running_mean torch.Size([128])
# px.model.6.running_var torch.Size([128])
# px.model.6.num_batches_tracked torch.Size([])
# px.model.8.weight torch.Size([2, 128])
# px.model.8.bias torch.Size([2])
# pzv.h0 torch.Size([1, 2])
# pzv.c0 torch.Size([1, 2])
# pzv.lstm.weight_ih torch.Size([8, 2])
# pzv.lstm.weight_hh torch.Size([8, 2])
# pzv.lstm.bias_ih torch.Size([8])
# pzv.lstm.bias_hh torch.Size([8])
# pzw.h0 torch.Size([1, 40])
# pzw.c0 torch.Size([1, 40])
# pzw.lstm.weight_ih torch.Size([160, 40])
# pzw.lstm.weight_hh torch.Size([160, 40])
# pzw.lstm.bias_ih torch.Size([160])
# pzw.lstm.bias_hh torch.Size([160])
# qw.linear.weight torch.Size([15, 20])
# qw.linear.bias torch.Size([15])
# qy.linear.weight torch.Size([2, 22])
# qy.linear.bias torch.Size([2])


"""
latent_w_priors torch.Size([40])
latent_v_priors torch.Size([2])
model_func.input.weight torch.Size([512, 2])
model_func.input.bias torch.Size([512])
model_func.hiddens.0.weight torch.Size([512, 512])
model_func.hiddens.0.bias torch.Size([512])
model_func.hiddens.1.weight torch.Size([512, 512])
model_func.hiddens.1.bias torch.Size([512])
model_func.output.weight torch.Size([512, 512])
model_func.output.bias torch.Size([512])
cla_func.linear.weight torch.Size([2, 512])
cla_func.linear.bias torch.Size([2])
static_prior.dummy_param torch.Size([0])
dynamic_w_prior.h0 torch.Size([1, 40])
dynamic_w_prior.c0 torch.Size([1, 40])
dynamic_w_prior.lstm.weight_ih torch.Size([160, 40])
dynamic_w_prior.lstm.weight_hh torch.Size([160, 40])
dynamic_w_prior.lstm.bias_ih torch.Size([160])
dynamic_w_prior.lstm.bias_hh torch.Size([160])
dynamic_w_prior.fc_affine_layer.weight torch.Size([40, 40])
dynamic_w_prior.fc_affine_layer.bias torch.Size([40])
dynamic_v_prior.h0 torch.Size([1, 4])
dynamic_v_prior.c0 torch.Size([1, 4])
dynamic_v_prior.lstm.weight_ih torch.Size([16, 2])
dynamic_v_prior.lstm.weight_hh torch.Size([16, 4])
dynamic_v_prior.lstm.bias_ih torch.Size([16])
dynamic_v_prior.lstm.bias_hh torch.Size([16])
dynamic_v_prior.fc_affine_layer.weight torch.Size([2, 4])
dynamic_v_prior.fc_affine_layer.bias torch.Size([2])
static_encoder.model_func.input.weight torch.Size([512, 2])
static_encoder.model_func.input.bias torch.Size([512])
static_encoder.model_func.hiddens.0.weight torch.Size([512, 512])
static_encoder.model_func.hiddens.0.bias torch.Size([512])
static_encoder.model_func.hiddens.1.weight torch.Size([512, 512])
static_encoder.model_func.hiddens.1.bias torch.Size([512])
static_encoder.model_func.output.weight torch.Size([512, 512])
static_encoder.model_func.output.bias torch.Size([512])
static_encoder.conv_fc.0.model.0.weight torch.Size([512, 512])
static_encoder.conv_fc.0.model.0.bias torch.Size([512])
static_encoder.conv_fc.0.model.1.weight torch.Size([512])
static_encoder.conv_fc.0.model.1.bias torch.Size([512])
static_encoder.conv_fc.0.model.1.running_mean torch.Size([512])
static_encoder.conv_fc.0.model.1.running_var torch.Size([512])
static_encoder.conv_fc.0.model.1.num_batches_tracked torch.Size([])
static_encoder.bi_lstm_layer.weight_ih_l0 torch.Size([80, 512])
static_encoder.bi_lstm_layer.weight_hh_l0 torch.Size([80, 20])
static_encoder.bi_lstm_layer.bias_ih_l0 torch.Size([80])
static_encoder.bi_lstm_layer.bias_hh_l0 torch.Size([80])
static_encoder.bi_lstm_layer.weight_ih_l0_reverse torch.Size([80, 512])
static_encoder.bi_lstm_layer.weight_hh_l0_reverse torch.Size([80, 20])
static_encoder.bi_lstm_layer.bias_ih_l0_reverse torch.Size([80])
static_encoder.bi_lstm_layer.bias_hh_l0_reverse torch.Size([80])
static_encoder.fc_affine_layer.model.0.weight torch.Size([40, 40])
static_encoder.fc_affine_layer.model.0.bias torch.Size([40])
dynamic_w_encoder.model_func.input.weight torch.Size([512, 2])
dynamic_w_encoder.model_func.input.bias torch.Size([512])
dynamic_w_encoder.model_func.hiddens.0.weight torch.Size([512, 512])
dynamic_w_encoder.model_func.hiddens.0.bias torch.Size([512])
dynamic_w_encoder.model_func.hiddens.1.weight torch.Size([512, 512])
dynamic_w_encoder.model_func.hiddens.1.bias torch.Size([512])
dynamic_w_encoder.model_func.output.weight torch.Size([512, 512])
dynamic_w_encoder.model_func.output.bias torch.Size([512])
dynamic_w_encoder.conv_fc.0.model.0.weight torch.Size([512, 512])
dynamic_w_encoder.conv_fc.0.model.0.bias torch.Size([512])
dynamic_w_encoder.conv_fc.0.model.1.weight torch.Size([512])
dynamic_w_encoder.conv_fc.0.model.1.bias torch.Size([512])
dynamic_w_encoder.conv_fc.0.model.1.running_mean torch.Size([512])
dynamic_w_encoder.conv_fc.0.model.1.running_var torch.Size([512])
dynamic_w_encoder.conv_fc.0.model.1.num_batches_tracked torch.Size([])
dynamic_w_encoder.z_lstm.weight_ih_l0 torch.Size([160, 512])
dynamic_w_encoder.z_lstm.weight_hh_l0 torch.Size([160, 40])
dynamic_w_encoder.z_lstm.bias_ih_l0 torch.Size([160])
dynamic_w_encoder.z_lstm.bias_hh_l0 torch.Size([160])
dynamic_w_encoder.fc_affine_layer.weight torch.Size([40, 40])
dynamic_w_encoder.fc_affine_layer.bias torch.Size([40])
dynamic_v_encoder.proj.0.weight torch.Size([128, 2])
dynamic_v_encoder.proj.0.bias torch.Size([128])
dynamic_v_encoder.proj.1.weight torch.Size([128])
dynamic_v_encoder.proj.1.bias torch.Size([128])
dynamic_v_encoder.proj.1.running_mean torch.Size([128])
dynamic_v_encoder.proj.1.running_var torch.Size([128])
dynamic_v_encoder.proj.1.num_batches_tracked torch.Size([])
dynamic_v_encoder.proj.3.weight torch.Size([64, 128])
dynamic_v_encoder.proj.3.bias torch.Size([64])
dynamic_v_encoder.conv_fc.0.model.0.weight torch.Size([64, 64])
dynamic_v_encoder.conv_fc.0.model.0.bias torch.Size([64])
dynamic_v_encoder.conv_fc.0.model.1.weight torch.Size([64])
dynamic_v_encoder.conv_fc.0.model.1.bias torch.Size([64])
dynamic_v_encoder.conv_fc.0.model.1.running_mean torch.Size([64])
dynamic_v_encoder.conv_fc.0.model.1.running_var torch.Size([64])
dynamic_v_encoder.conv_fc.0.model.1.num_batches_tracked torch.Size([])
dynamic_v_encoder.z_lstm.weight_ih_l0 torch.Size([8, 64])
dynamic_v_encoder.z_lstm.weight_hh_l0 torch.Size([8, 2])
dynamic_v_encoder.z_lstm.bias_ih_l0 torch.Size([8])
dynamic_v_encoder.z_lstm.bias_hh_l0 torch.Size([8])
dynamic_v_encoder.fc_affine_layer.weight torch.Size([2, 2])
dynamic_v_encoder.fc_affine_layer.bias torch.Size([2])
decoder.model.0.weight torch.Size([16, 40])
decoder.model.0.bias torch.Size([16])
decoder.model.2.weight torch.Size([64, 16])
decoder.model.2.bias torch.Size([64])
decoder.model.3.weight torch.Size([64])
decoder.model.3.bias torch.Size([64])
decoder.model.3.running_mean torch.Size([64])
decoder.model.3.running_var torch.Size([64])
decoder.model.3.num_batches_tracked torch.Size([])
decoder.model.5.weight torch.Size([128, 64])
decoder.model.5.bias torch.Size([128])
decoder.model.6.weight torch.Size([128])
decoder.model.6.bias torch.Size([128])
decoder.model.6.running_mean torch.Size([128])
decoder.model.6.running_var torch.Size([128])
decoder.model.6.num_batches_tracked torch.Size([])
decoder.model.8.weight torch.Size([2, 128])
decoder.model.8.bias torch.Size([2])
category_cla_func.linear.weight torch.Size([2, 22])
category_cla_func.linear.bias torch.Size([2])
"""
